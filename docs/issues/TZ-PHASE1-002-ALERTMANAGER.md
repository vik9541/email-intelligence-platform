# –¢–ó-002: Deploy AlertManager Configuration [Phase 1]

**–°—Ç–∞—Ç—É—Å:** üî¥ Not Started  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (Critical - Alert Routing)  
**–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏:** 2h  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** MEDIUM  
**–í–ª–∞–¥–µ–ª–µ—Ü:** DevOps/SRE  
**Sprint:** Phase 1 - Production Monitoring Stack  

---

## üìã Context (–ö–æ–Ω—Ç–µ–∫—Å—Ç)

AlertManager - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–æ—É—Ç–∏–Ω–≥–∞ –∏ —ç—Å–∫–∞–ª–∞—Ü–∏–∏ alerts –æ—Ç Prometheus. –§–∞–π–ª `prometheus/alertmanager.yml` —É–∂–µ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç:
- **3 —É—Ä–æ–≤–Ω—è —ç—Å–∫–∞–ª–∞—Ü–∏–∏:** P0 (PagerDuty), P1 (Slack + Email), P2 (Email only)
- **Smart routing:** –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ severity –∏ route –∫ –Ω—É–∂–Ω—ã–º receivers
- **Inhibit rules:** –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ derivative alerts (–Ω–∞–ø—Ä–∏–º–µ—Ä, latency alerts –∫–æ–≥–¥–∞ service down)
- **Grouping:** –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö alerts –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è noise

–ë–µ–∑ AlertManager'–∞ –≤—Å–µ Prometheus alerts –±—É–¥—É—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è, –Ω–æ –Ω–∏–∫—Ç–æ –∏—Ö –Ω–µ –ø–æ–ª—É—á–∏—Ç.

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
- ‚úÖ [–¢–ó-001: Prometheus SLO Rules deployed](TZ-PHASE1-001-PROMETHEUS-SLO-RULES.md)
- ‚è∏Ô∏è **–¢—Ä–µ–±—É–µ—Ç—Å—è:** Slack webhook URL, PagerDuty integration key, SMTP credentials
- ‚úÖ –§–∞–π–ª `prometheus/alertmanager.yml` —Å–æ–∑–¥–∞–Ω (commit 49e37eb)

---

## ‚úÖ Requirements (–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è)

### 1. –°–æ–∑–¥–∞—Ç—å Kubernetes Secrets –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π

```bash
# PagerDuty integration key
kubectl create secret generic pagerduty-key -n monitoring \
  --from-literal=integration_key='YOUR_PAGERDUTY_INTEGRATION_KEY'

# Slack webhook URL
kubectl create secret generic slack-webhook -n monitoring \
  --from-literal=url='https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

# SMTP credentials –¥–ª—è email alerts
kubectl create secret generic smtp-credentials -n monitoring \
  --from-literal=username='alerts@97v.ru' \
  --from-literal=password='YOUR_SMTP_PASSWORD'
```

### 2. –û–±–Ω–æ–≤–∏—Ç—å AlertManager ConfigMap

```bash
# –°–æ–∑–¥–∞—Ç—å ConfigMap –∏–∑ alertmanager.yml
kubectl create configmap alertmanager-config -n monitoring \
  --from-file=alertmanager.yml=prometheus/alertmanager.yml

# Verify: ConfigMap —Å–æ–∑–¥–∞–Ω
kubectl get configmap alertmanager-config -n monitoring -o yaml
```

### 3. Deploy/Update AlertManager

```bash
# –ï—Å–ª–∏ AlertManager –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
helm upgrade --install alertmanager prometheus-community/alertmanager \
  --namespace monitoring \
  --set configmapReload.enabled=true \
  --set config.existingConfigMap=alertmanager-config

# –ï—Å–ª–∏ AlertManager —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
kubectl rollout restart deployment/alertmanager -n monitoring
```

### 4. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Prometheus ‚Üí AlertManager —Å–≤—è–∑—å

–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ Prometheus –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç alerts –≤ AlertManager:

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Prometheus config
kubectl get configmap prometheus-config -n monitoring -o yaml | grep alertmanagers -A 10

# –î–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets:
#           - alertmanager:9093
```

–ï—Å–ª–∏ –Ω–µ—Ç, –æ–±–Ω–æ–≤–∏—Ç—å Prometheus config:

```yaml
# prometheus-config.yaml
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager.monitoring.svc.cluster.local:9093
```

### 5. –°–æ–∑–¥–∞—Ç—å Slack channels

–í Slack workspace —Å–æ–∑–¥–∞—Ç—å –∫–∞–Ω–∞–ª—ã:
- `#incidents` - –¥–ª—è P0 critical alerts
- `#alerts` - –¥–ª—è P1/P2 warnings

–î–æ–±–∞–≤–∏—Ç—å Incoming Webhook Integration –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞.

### 6. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å PagerDuty

1. –°–æ–∑–¥–∞—Ç—å Service –≤ PagerDuty: "Email Intelligence Platform - Production"
2. –î–æ–±–∞–≤–∏—Ç—å Integration: "Prometheus" type
3. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å Integration Key ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ Secret (—à–∞–≥ 1)

---

## ‚úÖ Acceptance Criteria (–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏–µ–º–∫–∏)

- [x] **AC1:** Secrets —Å–æ–∑–¥–∞–Ω—ã –≤ namespace `monitoring`:
  - `pagerduty-key`
  - `slack-webhook`
  - `smtp-credentials`
- [x] **AC2:** AlertManager ConfigMap —Å–æ–∑–¥–∞–Ω –∏–∑ `alertmanager.yml`
- [x] **AC3:** AlertManager pod running –∏ healthy
- [x] **AC4:** Prometheus —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ AlertManager (–≤–∏–¥–Ω–æ –≤ Prometheus UI ‚Üí Status ‚Üí Runtime & Build Information)
- [x] **AC5:** AlertManager UI –¥–æ—Å—Ç—É–ø–µ–Ω: `http://alertmanager.monitoring:9093`
- [x] **AC6:** Test alert —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Slack #incidents
- [x] **AC7:** Inhibit rules —Ä–∞–±–æ—Ç–∞—é—Ç (–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ duplicate alerts)
- [x] **AC8:** Grouping —Ä–∞–±–æ—Ç–∞–µ—Ç (–ø–æ—Ö–æ–∂–∏–µ alerts –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ –æ–¥–Ω–æ notification)

---

## üß™ How to Test (–ö–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å)

### Test 1: Verify AlertManager Running

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å pod status
kubectl get pods -n monitoring -l app=alertmanager

# Expected output:
# NAME                           READY   STATUS    RESTARTS   AGE
# alertmanager-0                 1/1     Running   0          5m

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å logs
kubectl logs -n monitoring alertmanager-0 --tail=50

# –î–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
# "msg"="Completed loading of configuration file"
```

### Test 2: Verify Prometheus ‚Üí AlertManager Connection

```bash
# –û—Ç–∫—Ä—ã—Ç—å Prometheus UI
kubectl port-forward -n monitoring svc/prometheus 9090:9090

# –ü–µ—Ä–µ–π—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ: http://localhost:9090/status
# Section: "Alertmanagers" –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å:
# - Endpoint: alertmanager.monitoring.svc.cluster.local:9093
# - State: UP
# - Last Error: (empty)
```

### Test 3: Send Test Alert to Slack

```bash
# –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π alert –≤ AlertManager API
curl -XPOST http://alertmanager.monitoring:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "TestAlert",
      "severity": "critical",
      "service": "email"
    },
    "annotations": {
      "summary": "Test critical alert - ignore",
      "description": "This is a test alert from –¢–ó-002 verification"
    },
    "startsAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
    "endsAt": "'$(date -u -d '+5 minutes' +%Y-%m-%dT%H:%M:%SZ)'"
  }
]'

# Expected:
# - –ß–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥ alert –ø–æ—è–≤–∏—Ç—Å—è –≤ Slack #incidents
# - PagerDuty —Å–æ–∑–¥–∞—Å—Ç incident (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å PagerDuty UI)
# - Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ oncall engineer
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ Slack:**
- –°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
  - üö® **FIRING** - TestAlert
  - Severity: critical
  - Service: email
  - Summary: Test critical alert - ignore
  - –ö–Ω–æ–ø–∫–∞ "View in AlertManager"

### Test 4: Verify Grouping

```bash
# –û—Ç–ø—Ä–∞–≤–∏—Ç—å 3 –ø–æ—Ö–æ–∂–∏—Ö alerts –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
for i in {1..3}; do
  curl -XPOST http://alertmanager.monitoring:9093/api/v1/alerts -d "[
    {
      \"labels\": {
        \"alertname\": \"HighMemory\",
        \"severity\": \"warning\",
        \"pod\": \"email-service-$i\"
      },
      \"annotations\": {
        \"summary\": \"High memory on pod $i\"
      }
    }
  ]"
done

# Expected:
# - AlertManager –æ–±—ä–µ–¥–∏–Ω–∏—Ç 3 alerts –≤ –û–î–ù–û notification
# - Slack –ø–æ–ª—É—á–∏—Ç 1 —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º: "3 alerts grouped: HighMemory"
```

### Test 5: Verify Inhibit Rules

```bash
# –®–∞–≥ 1: –û—Ç–ø—Ä–∞–≤–∏—Ç—å EmailServiceDown (P0)
curl -XPOST http://alertmanager.monitoring:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "EmailServiceDown",
      "severity": "critical",
      "service": "email"
    },
    "annotations": {
      "summary": "Service is completely down"
    }
  }
]'

# –®–∞–≥ 2: –û—Ç–ø—Ä–∞–≤–∏—Ç—å SLOLatencyP99Critical (derivative alert)
curl -XPOST http://alertmanager.monitoring:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "SLOLatencyP99Critical",
      "severity": "critical",
      "service": "email"
    },
    "annotations": {
      "summary": "Latency is high"
    }
  }
]'

# Expected:
# - Slack –ø–æ–ª—É—á–∏—Ç —Ç–æ–ª—å–∫–æ 1 notification: EmailServiceDown
# - SLOLatencyP99Critical –ø–æ–¥–∞–≤–ª–µ–Ω (inhibited), —Ç.–∫. service down
#
# Rationale: –ï—Å–ª–∏ —Å–µ—Ä–≤–∏—Å —É–ø–∞–ª, latency alerts –Ω–µ –∏–º–µ—é—Ç —Å–º—ã—Å–ª–∞
```

### Test 6: Verify Email Escalation (P1)

```bash
# –û—Ç–ø—Ä–∞–≤–∏—Ç—å P1 alert
curl -XPOST http://alertmanager.monitoring:9093/api/v1/alerts -d '[
  {
    "labels": {
      "alertname": "SLOAvailabilityWarning",
      "severity": "warning",
      "service": "email"
    },
    "annotations": {
      "summary": "Availability dropped to 99.5%"
    }
  }
]'

# Expected:
# - Slack #alerts –ø–æ–ª—É—á–∏—Ç notification (–ù–ï #incidents!)
# - Email –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ oncall@97v.ru
# - PagerDuty –ù–ï —Å–æ–∑–¥–∞–µ—Ç incident (—Ç–æ–ª—å–∫–æ –¥–ª—è critical)
```

---

## üìä Monitoring After Deployment

–ü–æ—Å–ª–µ deployment –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ AlertManager:

```bash
# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö alerts
curl -s http://alertmanager.monitoring:9093/api/v1/alerts | jq '.data | length'

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ notifications
curl -s http://alertmanager.monitoring:9093/metrics | grep alertmanager_notifications_total

# Expected output:
# alertmanager_notifications_total{integration="slack-critical"} 5
# alertmanager_notifications_total{integration="pagerduty-critical"} 2
# alertmanager_notifications_total{integration="email-oncall"} 8
```

---

## üîß Troubleshooting

### Problem: Slack notifications –Ω–µ –ø—Ä–∏—Ö–æ–¥—è—Ç

**Diagnosis:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å logs AlertManager
kubectl logs -n monitoring alertmanager-0 | grep slack

# –ò—Å–∫–∞—Ç—å –æ—à–∏–±–∫–∏:
# - "failed to notify slack" ‚Üí –Ω–µ–≤–µ—Ä–Ω—ã–π webhook URL
# - "context deadline exceeded" ‚Üí Slack –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
# - "invalid_payload" ‚Üí –ø—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏—è
```

**Fix:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Secret
kubectl get secret slack-webhook -n monitoring -o yaml

# –ï—Å–ª–∏ URL –Ω–µ–≤–µ—Ä–Ω—ã–π - –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å:
kubectl delete secret slack-webhook -n monitoring
kubectl create secret generic slack-webhook -n monitoring \
  --from-literal=url='https://hooks.slack.com/services/CORRECT/URL'

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å AlertManager
kubectl rollout restart deployment/alertmanager -n monitoring
```

### Problem: PagerDuty incidents –Ω–µ —Å–æ–∑–¥–∞—é—Ç—Å—è

**Diagnosis:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å integration key –≤ PagerDuty UI
# Services ‚Üí Email Intelligence Platform ‚Üí Integrations ‚Üí Prometheus

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å logs
kubectl logs -n monitoring alertmanager-0 | grep pagerduty
```

**Fix:**
```bash
# Verify integration key format (32 —Å–∏–º–≤–æ–ª–∞ hex)
kubectl get secret pagerduty-key -n monitoring -o jsonpath='{.data.integration_key}' | base64 -d

# –ï—Å–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π:
kubectl delete secret pagerduty-key -n monitoring
kubectl create secret generic pagerduty-key -n monitoring \
  --from-literal=integration_key='CORRECT_32_CHAR_HEX_KEY'
```

### Problem: Emails –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è

**Diagnosis:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SMTP credentials
kubectl get secret smtp-credentials -n monitoring -o yaml

# –¢–µ—Å—Ç SMTP connection
kubectl run smtp-test --rm -it --restart=Never --image=alpine -- \
  sh -c "apk add --no-cache curl && curl -v smtp://smtp.gmail.com:587"
```

**Fix:**
```bash
# –ï—Å–ª–∏ Gmail - —Ç—Ä–µ–±—É–µ—Ç—Å—è App Password, –Ω–µ –æ–±—ã—á–Ω—ã–π –ø–∞—Ä–æ–ª—å
# 1. –ü–µ—Ä–µ–π—Ç–∏: https://myaccount.google.com/apppasswords
# 2. –°–æ–∑–¥–∞—Ç—å App Password –¥–ª—è "Mail"
# 3. –û–±–Ω–æ–≤–∏—Ç—å Secret:

kubectl delete secret smtp-credentials -n monitoring
kubectl create secret generic smtp-credentials -n monitoring \
  --from-literal=username='alerts@97v.ru' \
  --from-literal=password='NEW_APP_PASSWORD_16_CHARS'
```

---

## üìã Checklist –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º –∑–∞–¥–∞—á–∏

- [ ] –í—Å–µ 3 Secrets —Å–æ–∑–¥–∞–Ω—ã –∏ –≤–∞–ª–∏–¥–Ω—ã
- [ ] AlertManager pod –≤ —Å—Ç–∞—Ç—É—Å–µ Running >5 –º–∏–Ω—É—Ç –±–µ–∑ restarts
- [ ] Test alert —É—Å–ø–µ—à–Ω–æ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω –≤:
  - [ ] Slack #incidents (P0)
  - [ ] Slack #alerts (P1)
  - [ ] PagerDuty (P0)
  - [ ] Email oncall (P1)
- [ ] Grouping —Ä–∞–±–æ—Ç–∞–µ—Ç (–Ω–µ—Å–∫–æ–ª—å–∫–æ alerts ‚Üí –æ–¥–Ω–æ notification)
- [ ] Inhibit rules —Ä–∞–±–æ—Ç–∞—é—Ç (derivative alerts –ø–æ–¥–∞–≤–ª—è—é—Ç—Å—è)
- [ ] AlertManager metrics —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –≤ Prometheus
- [ ] –°–æ–∑–¥–∞–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: "How to add new receiver" –≤ wiki

---

## üîó Related Tasks

- **Previous:** [–¢–ó-001: Deploy Prometheus SLO Rules](TZ-PHASE1-001-PROMETHEUS-SLO-RULES.md)
- **Next:** [–¢–ó-003: Create Grafana SLO Dashboard](TZ-PHASE1-003-GRAFANA-DASHBOARD.md)
- **Dependency:** Prometheus –¥–æ–ª–∂–µ–Ω –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å alerts (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¢–ó-001)

---

## üìù Notes

### AlertManager Routing Logic

```yaml
route:
  group_by: ['alertname', 'cluster']
  group_wait: 10s        # –ñ–¥–∞—Ç—å 10s –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π (–¥–ª—è grouping)
  group_interval: 10s    # –ï—Å–ª–∏ –Ω–æ–≤—ã–π alert –≤ —Ç–æ–π –∂–µ –≥—Ä—É–ø–ø–µ - –ø–æ–¥–æ–∂–¥–∞—Ç—å 10s
  repeat_interval: 12h   # –ü–æ–≤—Ç–æ—Ä—è—Ç—å notification –∫–∞–∂–¥—ã–µ 12 —á–∞—Å–æ–≤ –µ—Å–ª–∏ alert still firing
  
  routes:
    # P0: PagerDuty + Slack + Incident Webhook
    - match:
        severity: critical
      receiver: pagerduty-critical
      group_wait: 5s       # –ö—Ä–∏—Ç–∏—á–Ω–æ - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –±—ã—Å—Ç—Ä–µ–µ
      continue: true       # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∫ —Å–ª–µ–¥—É—é—â–∏–º routes
    
    # P1: Slack + Email
    - match:
        severity: warning
      receiver: slack-high
      continue: true
    
    # P2: Email only
    - match:
        severity: info
      receiver: email-team
```

### Inhibit Rules Explained

```yaml
# –ï—Å–ª–∏ EmailServiceDown firing, –ø–æ–¥–∞–≤–∏—Ç—å –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ email service alerts
inhibit_rules:
  - source_match:
      alertname: EmailServiceDown
    target_match_re:
      alertname: SLO.*|Kafka.*|Postgres.*
    equal: ['service']

# Rationale: –ö–æ–≥–¥–∞ –≤–µ—Å—å —Å–µ—Ä–≤–∏—Å —É–ø–∞–ª, –Ω–µ –Ω—É–∂–Ω—ã –∞–ª–µ—Ä—Ç—ã –ø—Ä–æ latency, throughput, etc.
```

---

**–°–æ–∑–¥–∞–Ω–æ:** 14 –¥–µ–∫–∞–±—Ä—è 2025  
**–ê–≤—Ç–æ—Ä:** DevOps Team  
**–í–µ—Ä—Å–∏—è:** 1.0
